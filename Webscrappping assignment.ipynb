{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330f8287-5edf-4134-88cf-7681074a96e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41d610b-bfd8-44cf-997c-c76b928a7354",
   "metadata": {},
   "outputs": [],
   "source": [
    "Web Scraping is a technique of extracting data from websites. It involves fetching the web page's HTML \n",
    "code and then extracting specific information from it, either manually or using automated scripts.\n",
    "Web scraping is used to gather data for various purposes, including research, analysis, and automation.\n",
    "\n",
    "Three areas where web scraping is commonly used include:\n",
    "\n",
    "Business Intelligence and Market Research: Companies use web scraping to collect data about their\n",
    "competitors, market trends, and customer sentiments. This information helps in making informed business \n",
    "decisions.\n",
    "\n",
    "Price Monitoring and Comparison: E-commerce websites often use web scraping to monitor competitors\n",
    " prices and adjust their own pricing strategies accordingly. Consumers also use scraping tools to \n",
    "compare prices across different platforms.\n",
    "\n",
    "Content Aggregation and News Monitoring: Media outlets and content aggregators use web scraping to gather\n",
    "news articles, blog posts, and other content from various sources. This enables them to provide a \n",
    "centralized hub for users to access diverse information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8431d85-2803-42ef-83f2-d05b62256d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "There are several methods for web scraping, but two primary approaches are:\n",
    "\n",
    "Manual Web Scraping: This involves manually copying and pasting data from websites into a spreadsheet \n",
    "or another tool. While simple, it's time-consuming and not suitable for large-scale data extraction.\n",
    "\n",
    "Automated Web Scraping: This involves using programming scripts or tools to automatically extract data\n",
    "from websites. Common programming languages for automated web scraping include Python (using libraries \n",
    "like Beautiful Soup and Scrapy), JavaScript (using tools like Puppeteer), and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443658bc-c88e-4c51-8fa4-80d65ff579bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "Beautiful Soup is a Python library used for web scraping purposes to pull the data out of HTML and XML\n",
    "files. It provides Pythonic idioms for iterating, searching, and modifying the parse tree. Beautiful\n",
    "Soup makes it easy to scrape information from web pages and extract the required data by providing\n",
    "methods to navigate and search the parse tree.\n",
    "\n",
    "It's used because:\n",
    "\n",
    "Parse Tree Navigation: Beautiful Soup provides methods and Pythonic idioms for iterating, searching, \n",
    "and modifying the parse tree. This makes it easy to navigate the HTML or XML structure.\n",
    "\n",
    "Tag Searching: It allows you to search for tags, filter them based on various criteria, and \n",
    "extract the data within those tags.\n",
    "\n",
    "Integration with Parser Libraries: Beautiful Soup supports various parsers, including\n",
    "Python's built-in HTML parser, lxml, and others, making it versatile in handling different types of HTML structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e83d56-46a7-48a1-9a9f-9c885a9d2dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Why is Flask used in this Web Scraping project?\n",
    "\n",
    "Flask is a web framework for Python, and it is often used in web scraping projects for several reasons:\n",
    "\n",
    "Lightweight: Flask is a micro-framework, meaning it is lightweight and easy to use. For a simple web scraping project that involves displaying scraped data on a web page, Flask is a suitable choice without unnecessary complexity.\n",
    "\n",
    "Rapid Development: Flask allows for rapid development of web applications. In a web scraping project, where the main focus might be on the scraping logic rather than building a complex web application, Flask's simplicity is beneficial.\n",
    "\n",
    "Integration: Flask integrates well with other Python libraries and tools, including those used for web scraping, such as Beautiful Soup for parsing HTML.\n",
    "\n",
    "Scalability: While Flask is lightweight, it can be extended and scaled for larger projects if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87596527-aa0f-44f1-9964-ef78c36e0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13638c2d-beaa-4c98-8baf-bd6ee703a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "Service used in project is Code pipeline and beanstack\n",
    "\n",
    "AWS CodePipeline:\n",
    "AWS CodePipeline is a continuous integration and continuous delivery (CI/CD) service. It automates the \n",
    "build, test, and deployment phases of releasing software. It allows you to define and model your release\n",
    "process, automate the build and deployment stages, and manage the workflow of your software delivery \n",
    "pipeline.\n",
    "\n",
    "AWS Elastic Beanstalk:\n",
    "AWS Elastic Beanstalk is a fully managed service that makes it easy to deploy and run applications in\n",
    "multiple languages. It abstracts the complexity of infrastructure management, allowing developers to \n",
    "focus on writing code. It supports various programming languages, frameworks, and web containers.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
